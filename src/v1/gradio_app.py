"""
Gradio Web Interface for AI vs Human Text Detection
User-friendly interface for testing the trained model
"""
import gradio as gr
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Tuple, Optional
import logging
import os
from src.v1.prediction import TextPredictor
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings("ignore")

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GradioInterface:
    """Gradio interface for AI vs Human text detection"""
    
    def __init__(self, model_path: str = "./model_output"):
        """
        Initialize the Gradio interface.
        
        Args:
            model_path (str): Path to trained model
        """
        self.model_path = model_path
        self.predictor = None
        
        # Try to load the model
        self._load_model()
        
        # Set up the interface
        self.interface = self._create_interface()
    
    def _load_model(self):
        """Load the trained model"""
        try:
            if os.path.exists(self.model_path):
                logger.info(f"Loading model from {self.model_path}")
                self.predictor = TextPredictor(self.model_path)
                logger.info("Model loaded successfully")
            else:
                logger.warning(f"Model path {self.model_path} does not exist")
                self.predictor = None
        except Exception as e:
            logger.error(f"Error loading model: {str(e)}")
            self.predictor = None
    
    def predict_text(self, text: str) -> Tuple[str, str, str, str]:
        """
        Predict whether text is AI-generated or human-written.
        
        Args:
            text (str): Input text to analyze
            
        Returns:
            Tuple[str, str, str, str]: Prediction, confidence, details, and advice
        """
        if not text.strip():
            return "Please enter some text to analyze.", "", "", ""
        
        if self.predictor is None:
            return "Model not loaded. Please check the model path.", "", "", ""
        
        try:
            # Get prediction
            result = self.predictor.predict_single_text(text)
            
            # Format main prediction
            prediction = result['transformer_prediction']
            confidence = result['transformer_confidence']
            
            prediction_text = f"**{prediction}**"
            confidence_text = f"Confidence: **{confidence:.1%}**"
            
            # Format detailed results
            details = self._format_detailed_results(result)
            
            # Generate advice
            advice = self._generate_advice(result)
            
            return prediction_text, confidence_text, details, advice
            
        except Exception as e:
            logger.error(f"Error in prediction: {str(e)}")
            return f"Error: {str(e)}", "", "", ""
    
    def _format_detailed_results(self, result: Dict) -> str:
        """Format detailed results for display"""
        details = []
        
        # Basic statistics
        details.append("### ðŸ“Š Text Statistics")
        details.append(f"- **Word count:** {result['word_count']}")
        details.append(f"- **Character count:** {result['character_count']}")
        details.append("")
        
        # Probability breakdown
        details.append("### ðŸŽ¯ Probability Breakdown")
        details.append(f"- **Human-written probability:** {result['human_probability']:.1%}")
        details.append(f"- **AI-generated probability:** {result['ai_probability']:.1%}")
        details.append("")
        
        return "\n".join(details)
    
    def _generate_advice(self, result: Dict) -> str:
        """Generate advice based on prediction results"""
        advice = []
        
        confidence = result['transformer_confidence']
        prediction = result['transformer_prediction']
        
        advice.append("### ðŸ’¡ Interpretation Guide")
        
        if confidence > 0.9:
            advice.append("- **Very High Confidence:** The model is very certain about this prediction.")
        elif confidence > 0.7:
            advice.append("- **High Confidence:** The model is fairly confident about this prediction.")
        elif confidence > 0.6:
            advice.append("- **Moderate Confidence:** The model shows some uncertainty. Consider the context.")
        else:
            advice.append("- **Low Confidence:** The model is uncertain. The text may have mixed characteristics.")
        
        advice.append("")
        advice.append("### ðŸŽ¯ What This Means")
        
        if prediction == "AI-Generated":
            advice.append("- The text shows patterns typically associated with AI-generated content")
            advice.append("- This could indicate use of language models like GPT, ChatGPT, or similar tools")
            advice.append("- Consider the writing style, coherence, and topic complexity")
        else:
            advice.append("- The text shows patterns typically associated with human writing")
            advice.append("- This suggests natural human composition with personal style and nuances")
            advice.append("- Human writing often shows more variability and personal touches")
        
        advice.append("")
        advice.append("### âš ï¸ Important Notes")
        advice.append("- This is a probabilistic prediction, not a definitive judgment")
        advice.append("- AI detection is an evolving field with inherent limitations")
        advice.append("- Consider multiple factors beyond just this tool's output")
        advice.append("- Human-AI collaboration is becoming increasingly common")
        
        return "\n".join(advice)
    
    def analyze_batch_text(self, file) -> Tuple[str, str]:
        """
        Analyze a batch of texts from uploaded file.
        
        Args:
            file: Uploaded CSV file
            
        Returns:
            Tuple[str, str]: Results summary and detailed results
        """
        if file is None:
            return "Please upload a CSV file.", ""
        
        if self.predictor is None:
            return "Model not loaded. Please check the model path.", ""
        
        try:
            # Read the CSV file
            df = pd.read_csv(file.name)
            
            # Check if required columns exist
            if 'text' not in df.columns:
                return "CSV file must contain a 'text' column.", ""
            
            # Limit to first 100 rows for demo purposes
            if len(df) > 100:
                df = df.head(100)
                warning_msg = f"Limited analysis to first 100 rows (original file had {len(df)} rows).\n\n"
            else:
                warning_msg = ""
            
            # Get predictions
            texts = df['text'].tolist()
            results = self.predictor.predict_batch(texts)
            
            # Process results
            predictions = []
            confidences = []
            ai_probs = []
            
            for result in results:
                pred_binary = 1 if result['transformer_prediction'] == 'AI-Generated' else 0
                predictions.append(pred_binary)
                confidences.append(result['transformer_confidence'])
                ai_probs.append(result['ai_probability'])
            
            # Calculate summary statistics
            total_texts = len(predictions)
            ai_count = sum(predictions)
            human_count = total_texts - ai_count
            avg_confidence = np.mean(confidences)
            
            # Create summary
            summary = f"""{warning_msg}### ðŸ“ˆ Batch Analysis Results
            
**Total texts analyzed:** {total_texts}
- **AI-generated:** {ai_count} ({ai_count/total_texts:.1%})
- **Human-written:** {human_count} ({human_count/total_texts:.1%})
- **Average confidence:** {avg_confidence:.1%}

### ðŸ“Š Distribution
The pie chart shows the distribution of predictions across your texts."""
            
            # Create results DataFrame
            results_df = pd.DataFrame({
                'Text_ID': range(1, len(texts) + 1),
                'Prediction': ['AI-Generated' if p == 1 else 'Human-Written' for p in predictions],
                'Confidence': [f"{c:.1%}" for c in confidences],
                'AI_Probability': [f"{p:.1%}" for p in ai_probs],
                'Text_Preview': [t[:100] + '...' if len(t) > 100 else t for t in texts]
            })
            
            detailed_results = results_df.to_string(index=False, max_cols=5)
            
            return summary, detailed_results
            
        except Exception as e:
            logger.error(f"Error in batch analysis: {str(e)}")
            return f"Error processing file: {str(e)}", ""
    
    def _create_interface(self) -> gr.Interface:
        """Create the Gradio interface"""
        
        # Custom CSS for better styling
        css = """
        .gradio-container {
            font-family: 'Arial', sans-serif;
        }
        .prediction-output {
            font-size: 18px;
            font-weight: bold;
        }
        .confidence-output {
            font-size: 16px;
            color: #2563eb;
        }
        """
        
        with gr.Blocks(css=css, title="AI vs Human Text Detector", theme=gr.themes.Soft()) as interface:
            
            # Header
            gr.Markdown("""
            # ðŸ¤– AI vs Human Text Detector
            
            **Detect whether text is AI-generated or human-written using state-of-the-art transformer models.**
            
            This tool uses fine-tuned transformer models (DistilBERT/RoBERTa) to classify text with high accuracy.
            """)
            
            with gr.Tabs():
                
                # Single Text Analysis Tab
                with gr.TabItem("ðŸ“ Single Text Analysis"):
                    gr.Markdown("### Analyze a single piece of text")
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            text_input = gr.Textbox(
                                label="Enter text to analyze",
                                placeholder="Paste your text here... (minimum 50 characters recommended)",
                                lines=8,
                                max_lines=15
                            )
                            
                            with gr.Row():
                                analyze_btn = gr.Button("ðŸ” Analyze Text", variant="primary", size="lg")
                        
                        with gr.Column(scale=2):
                            with gr.Group():
                                prediction_output = gr.Markdown(label="Prediction", elem_classes=["prediction-output"])
                                confidence_output = gr.Markdown(label="Confidence", elem_classes=["confidence-output"])
                            
                            details_output = gr.Markdown(label="Detailed Analysis")
                            advice_output = gr.Markdown(label="Interpretation")
                    
                    # Example texts
                    gr.Markdown("### ðŸ“š Try These Examples")
                    
                    example_human = "I've been thinking about my childhood lately, and there's this one memory that keeps coming back to me. It was a summer afternoon when I was about eight years old, and my grandmother was teaching me how to make her famous apple pie. The kitchen smelled like cinnamon and butter, and I remember feeling so grown-up as she let me roll out the dough with her old wooden rolling pin."
                    
                    example_ai = "Artificial intelligence has revolutionized numerous industries and continues to transform the way we live and work. Machine learning algorithms have become increasingly sophisticated, enabling computers to perform complex tasks that were once thought to be exclusively human. From healthcare diagnostics to autonomous vehicles, AI applications are becoming more prevalent in our daily lives."
                    
                    with gr.Row():
                        gr.Examples(
                            examples=[
                                [example_human],
                                [example_ai]
                            ],
                            inputs=[text_input],
                            label="Click to try these examples"
                        )
                
                # Batch Analysis Tab
                with gr.TabItem("ðŸ“Š Batch Analysis"):
                    gr.Markdown("### Analyze multiple texts from a CSV file")
                    gr.Markdown("Upload a CSV file with a 'text' column to analyze multiple texts at once.")
                    
                    with gr.Row():
                        with gr.Column():
                            file_input = gr.File(
                                label="Upload CSV file",
                                file_types=[".csv"],
                                file_count="single"
                            )
                            batch_analyze_btn = gr.Button("ðŸ“ˆ Analyze Batch", variant="primary")
                        
                        with gr.Column():
                            batch_summary = gr.Markdown(label="Summary")
                    
                    batch_details = gr.Textbox(
                        label="Detailed Results",
                        lines=15,
                        max_lines=20,
                        show_copy_button=True
                    )
                
                # About Tab
                with gr.TabItem("â„¹ï¸ About"):
                    gr.Markdown("""
                    ### About This Tool
                    
                    This AI vs Human text detector uses state-of-the-art transformer models to classify text with high accuracy.
                    
                    #### ðŸ”¬ How It Works
                    - **Primary Model:** Fine-tuned transformer model (DistilBERT/RoBERTa/DeBERTa)
                    - **Training Data:** Kaggle AI vs Human dataset with thousands of examples
                    
                    #### ðŸ“Š Model Performance
                    - **Accuracy:** Typically 85-95% on test data
                    - **Speed:** Real-time inference for single texts
                    - **Robustness:** Tested on diverse text types and lengths
                    
                    #### âš ï¸ Limitations
                    - No detection method is 100% accurate
                    - Performance may vary with text length and domain
                    - AI technology is rapidly evolving
                    - Human-AI collaboration scenarios may be challenging to detect
                    
                    #### ðŸš€ Technical Details
                    - Built with PyTorch and Hugging Face Transformers
                    - Supports multiple model architectures
                    - Includes comprehensive evaluation metrics
                    - Ready for deployment on Hugging Face Spaces
                    
                    #### ðŸ“ Usage Tips
                    - Longer texts (>100 words) generally provide more reliable predictions
                    - Consider the confidence score when interpreting results
                    - Use batch analysis for processing multiple texts efficiently
                    - Combine with other detection methods for critical applications
                    """)
            
            # Event handlers
            analyze_btn.click(
                fn=self.predict_text,
                inputs=[text_input],
                outputs=[prediction_output, confidence_output, details_output, advice_output]
            )
            
            batch_analyze_btn.click(
                fn=self.analyze_batch_text,
                inputs=[file_input],
                outputs=[batch_summary, batch_details]
            )
        
        return interface

def launch_app(model_path: str = "./model_output", 
               share: bool = False, 
               port: int = 7860) -> gr.Interface:
    """
    Launch the Gradio web interface.
    
    Args:
        model_path (str): Path to trained model
        share (bool): Whether to create a public link
        port (int): Port to run the interface on
        
    Returns:
        gr.Interface: The Gradio interface object
    """
    logger.info("Launching Gradio interface...")
    
    # Create the interface
    interface_creator = GradioInterface(model_path)
    interface = interface_creator.interface
    
    # Launch the interface
    interface.launch(
        share=share,
        server_port=port,
        server_name="0.0.0.0",
        show_error=True
    )
    
    return interface

if __name__ == "__main__":
    # Launch the interface
    print("Starting AI vs Human Text Detector Web Interface...")
    
    # Check if model exists
    model_path = "./model_output"
    if not os.path.exists(model_path):
        print(f"Warning: Model path {model_path} does not exist.")
        print("Please train a model first or update the model_path.")
    
    # Launch the app
    launch_app(
        model_path=model_path,
        share=True,  # Set to True to create a public link
        port=7860
    )